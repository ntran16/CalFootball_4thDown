{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Most Similar Games\n",
    "\n",
    "Determine n most similar matchups based off of the ESPN efficiency rating for 1. Cal's offense and 2. the opponent's defense. I know we talked about determining the most similar matchups based off of 4 parameters (the offense and defense of both teams), but becuase we didn't decide how to weight the 4 parameters I use only 1. and 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import urllib.request\n",
    "from bs4 import BeautifulSoup\n",
    "from collections import Counter\n",
    "import csv\n",
    "import re\n",
    "from get_data import get_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Extracts ESPN Offensive and Defensive Efficieny Ratings from 2005-2017\n",
    "\n",
    "Returns:\n",
    "    2 Pandas Data Frames: \n",
    "        1. awayTeam, homeTeam, year\n",
    "        2. Def. Rating, Off. Rating, Team, year\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def get_ratings():\n",
    "    \n",
    "    def extract_team_name(x):\n",
    "            match = re.search('\\>([a-zA-Z\\s\\&\\;\\(\\)\\.\\']*)\\<\\/a\\>', x)\n",
    "            if match:\n",
    "                found = match.group(1)\n",
    "            return found\n",
    "\n",
    "    def extract_rating(x):\n",
    "            match = re.search('\\>(.*)\\<', x)\n",
    "            if match:\n",
    "                found = match.group(1)\n",
    "            return found\n",
    "        \n",
    "    pxp_data = get_data(\"all\")\n",
    "\n",
    "    game_data = pxp_data.groupby(pxp_data.gameId).first().loc[:, [\"awayTeam\", \"homeTeam\", \"year\"]]\n",
    "    game_data = game_data.loc[game_data.year >= 2005]\n",
    "    \n",
    "    ### Remove teams that were not DI for all years between 2005 and 2017\n",
    "    teams_to_remove = [\"Appalachian St\", \"Texas State\", \"W Kentucky\", \"UMass\", \"Ga Southern\", \"Georgia State\", \"South Alabama\"]\n",
    "\n",
    "    for x in teams_to_remove:\n",
    "        team_away = game_data.awayTeam == x\n",
    "        team_home = game_data.homeTeam == x\n",
    "        team_home = ~team_home.values\n",
    "        team_away = ~team_away.values\n",
    "        game_data = game_data[team_home*team_away]\n",
    "                \n",
    "    teams = []\n",
    "    off_eff = []\n",
    "    def_eff = []\n",
    "    year = []\n",
    "\n",
    "    ### Start of Web Scraper\n",
    "    for x in np.arange(2005, 2018):\n",
    "        url = \"http://www.espn.com/college-football/statistics/teamratings/_/year/\" + str(x) + \"/sort/offEfficiency/tab/efficiency\"\n",
    "        page = urllib.request.urlopen(url).read()\n",
    "        soup = BeautifulSoup(page)\n",
    "\n",
    "        raw_team_name = []\n",
    "        raw_off_rating = []\n",
    "        raw_def_rating = []\n",
    "\n",
    "        for tr in soup.find_all('tr')[1:]:\n",
    "            tds = tr.find_all('td')\n",
    "            team = tds[1]\n",
    "            off_rating = tds[2]\n",
    "            def_rating = tds[3]\n",
    "\n",
    "            raw_team_name.append(team)\n",
    "            raw_off_rating.append(off_rating)\n",
    "            raw_def_rating.append(def_rating)\n",
    "\n",
    "        raw_team_name = [str(x) for x in raw_team_name]\n",
    "        raw_team_name = raw_team_name[1:]\n",
    "        raw_team_name = np.array(raw_team_name)\n",
    "\n",
    "        column_headers = ~np.array([\"TEAM\" in x for x in raw_team_name])\n",
    "        raw_team_name = raw_team_name[column_headers]\n",
    "        team_names = [extract_team_name(x) for x in raw_team_name]\n",
    "\n",
    "        raw_off_rating = raw_off_rating[1:]\n",
    "        raw_off_rating = [str(x) for x in raw_off_rating]\n",
    "        raw_off_rating = np.array(raw_off_rating)\n",
    "        raw_off_rating = raw_off_rating[column_headers]\n",
    "\n",
    "        off_ratings = np.array([extract_rating(x) for x in raw_off_rating])\n",
    "        off_ratings = [float(x) for x in off_ratings]\n",
    "\n",
    "        raw_def_rating = raw_def_rating[1:]\n",
    "        raw_def_rating = [str(x) for x in raw_def_rating]\n",
    "        raw_def_rating = np.array(raw_def_rating)\n",
    "        raw_def_rating = raw_def_rating[column_headers]\n",
    "\n",
    "        def_ratings = np.array([extract_rating(x) for x in raw_def_rating])\n",
    "        def_ratings = [float(x) for x in def_ratings]\n",
    "\n",
    "        teams.append(team_names)\n",
    "        off_eff.append(off_ratings)\n",
    "        def_eff.append(def_ratings)\n",
    "        year.append([x]*len(team_names))\n",
    "\n",
    "    teams = sum(teams, [])\n",
    "    off_eff = sum(off_eff, [])\n",
    "    def_eff = sum(def_eff, [])\n",
    "    year = sum(year, [])\n",
    "    \n",
    "    ### Create Rating DataFrame\n",
    "    rating_data = pd.DataFrame({\"Team\" : teams, \"Off. Rating\" : off_eff, \"Year\" : year, \"Def. Rating\" : def_eff})\n",
    "\n",
    "    ### Rename Teams in the rating data so that it matches the game data\n",
    "    rating_data.Team = pd.Series([x.replace(\"Texas A&amp;M'\", \"Texas A&M\") for x in rating_data.Team.values])\n",
    "    rating_data.Team = pd.Series([x.replace(\"Texas A&amp;M\", \"Texas A&M\") for x in rating_data.Team.values])\n",
    "    rating_data.Team = pd.Series([x.replace(\"Mich. St.\", \"Michigan State\") for x in rating_data.Team.values])\n",
    "    rating_data.Team = pd.Series([x.replace(\"Oregon St\", \"Oregon State\") for x in rating_data.Team.values])\n",
    "    rating_data.Team = pd.Series([x.replace(\"Oregon Stateate\", \"Oregon State\") for x in rating_data.Team.values])\n",
    "\n",
    "    ### Remove games where teams are playing an opponent for which no rating data exists\n",
    "    keep_games = []\n",
    "    \n",
    "    for index, x in game_data.iterrows():\n",
    "        keep_game = x.awayTeam in rating_data.Team.values and x.homeTeam in rating_data.Team.values\n",
    "        keep_games.append(keep_game)\n",
    "\n",
    "    keep_games = np.array(keep_games)\n",
    "    game_data = game_data.loc[keep_games]\n",
    "    \n",
    "    return game_data, rating_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Uses ESPN Efficiency data from above to find the n most similar games\n",
    "\n",
    "Parameters: \n",
    "    off_rating - Offensive Rating of team of interest\n",
    "    def_rating - Deffensive Rating of team of interest\n",
    "    n - number of most similar games to be returned\n",
    "    game_data - First Dataframe returned by get_ratings()\n",
    "    rating_data - Second Dataframe returned by get_ratings()\n",
    "    \n",
    "Returns: \n",
    "    Array of lists where each list has the following elements:\n",
    "        1. String - name of AWAY team\n",
    "        2. String - name of HOME team\n",
    "        3. Int - year of matchup\n",
    "        4. Boolean - True if home team is on offense and away team is on defense (for False the sides are swapped)\n",
    "        5. Float - Root Mean Squared Error of matchup to matchup of interest\n",
    "        \n",
    "\"\"\"\n",
    "\n",
    "def most_similar(off_rating, def_rating, n, game_data, rating_data):\n",
    "    RMSEs = []\n",
    "    home_off_away_def = []\n",
    "\n",
    "    for index, x in game_data.iterrows():\n",
    "        x_year_ratings = rating_data.loc[rating_data.Year == x.year]\n",
    "        \n",
    "        away_def = float(x_year_ratings.loc[x_year_ratings.Team == x.awayTeam].loc[:, \"Def. Rating\"].values)\n",
    "        away_off = float(x_year_ratings.loc[x_year_ratings.Team == x.awayTeam].loc[:, \"Off. Rating\"].values)\n",
    "        home_def = float(x_year_ratings.loc[x_year_ratings.Team == x.homeTeam].loc[:, \"Def. Rating\"].values)\n",
    "        home_off = float(x_year_ratings.loc[x_year_ratings.Team == x.homeTeam].loc[:, \"Off. Rating\"].values)\n",
    "    \n",
    "        ### Use Root Mean Squared Error for Test Statistic\n",
    "        rmse_away_home = np.sqrt(((def_rating - away_def)**2 + (off_rating - home_off)**2)/2)\n",
    "        rmse_home_away = np.sqrt(((def_rating - home_def)**2 + (off_rating - away_off)**2)/2)\n",
    "        \n",
    "        if rmse_away_home < rmse_home_away:\n",
    "            home_off_away_def.append(True)\n",
    "        else:\n",
    "            home_off_away_def.append(False)\n",
    "    \n",
    "        game_rmse = np.array([rmse_away_home, rmse_home_away])\n",
    "        RMSEs.append(game_rmse[np.argmin(game_rmse)])\n",
    "    \n",
    "    game_data.loc[:,\"RMSEs\"] = RMSEs\n",
    "    game_data.loc[:, \"home_off_away_def\"] = home_off_away_def\n",
    "    \n",
    "    return game_data.sort_values(\"RMSEs\").reset_index().loc[0:n, [\"awayTeam\", \"homeTeam\", \"year\", \"home_off_away_def\", \"RMSEs\"]].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is an example of how the previous functions are used:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['Florida', 'Alabama', 2009, False, 0.09999999999999432],\n",
       "       ['LSU', 'Alabama', 2011, True, 0.31622776601684244],\n",
       "       ['Clemson', 'Louisville', 2017, True, 0.6964194138592112],\n",
       "       ['Ole Miss', 'Texas A&M', 2014, True, 1.2369316876853003],\n",
       "       ['Alabama', 'Miss St', 2015, True, 1.8110770276274808],\n",
       "       ['Florida', 'FSU', 2016, True, 2.0591260281973973],\n",
       "       ['Alabama', 'VT', 2009, True, 2.122498527679112],\n",
       "       ['Miss St', 'Ole Miss', 2014, False, 2.2461077445216184],\n",
       "       ['Clemson', 'NC State', 2017, True, 2.4869660230891824],\n",
       "       ['Oregon', 'USC', 2008, False, 2.526855753698658],\n",
       "       ['Arkansas', 'Alabama', 2009, False, 2.5465663156493643]], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "game_data, rating_data = get_ratings()\n",
    "most_similar(off_rating = 80, def_rating = 90, n = 10, game_data = game_data, rating_data = rating_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
